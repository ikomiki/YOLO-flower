{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "304906ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: mps\n"
     ]
    }
   ],
   "source": [
    "FLOWERS_DIR = './flower_photos'\n",
    "TRAIN_FRACTION = 0.8\n",
    "RANDOM_SEED = 2018\n",
    "# ã‚¯ãƒ©ã‚¹ã‚ãŸã‚Šã®å­¦ç¿’ç”¨ç”»åƒã®æœ€å¤§æ•°ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ã®ç”»åƒã‚’ä½¿ç”¨ï¼‰\n",
    "MAX_IMAGES_PER_CLASS = 100\n",
    "\n",
    "# ãƒ‡ãƒã‚¤ã‚¹ã‚’è‡ªå‹•æ±ºå®šï¼ˆMPSã€CUDAã€ã¾ãŸã¯CPUï¼‰\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccddcbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Grounding-DINOãŒåˆ©ç”¨å¯èƒ½ã§ã™\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Grounding-DINOã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰\n",
    "try:\n",
    "    from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "    import groundingdino.datasets.transforms as TS\n",
    "    GROUNDING_DINO_AVAILABLE = True\n",
    "    print(\"âœ“ Grounding-DINOãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "except ImportError as e:\n",
    "    print(\"è­¦å‘Š: Grounding-DINOãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:\")\n",
    "    print(f\"  ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}\")\n",
    "    GROUNDING_DINO_AVAILABLE = False\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab0f0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower photos are located in ./flower_photos\n"
     ]
    }
   ],
   "source": [
    "def download_images():\n",
    "  \"\"\"If the images aren't already downloaded, save them to FLOWERS_DIR.\"\"\"\n",
    "  if not os.path.exists(FLOWERS_DIR):\n",
    "    DOWNLOAD_URL = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "    print('Downloading flower images from %s...' % DOWNLOAD_URL)\n",
    "    urllib.request.urlretrieve(DOWNLOAD_URL, 'flower_photos.tgz')\n",
    "    !tar xfz flower_photos.tgz\n",
    "  print('Flower photos are located in %s' % FLOWERS_DIR)\n",
    "\n",
    "download_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "120d60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grounding-DINOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\n",
      "final text_encoder_type: bert-base-uncased\n",
      "Grounding-DINOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\n",
      "  æ³¨æ„: å‹•ä½œç¢ºèªã®ãŸã‚ã€daisyã¯100æšã®ã¿å‡¦ç†ã—ã¾ã™\n",
      "\n",
      "daisy (ã‚¯ãƒ©ã‚¹ID: 0): ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  daisy:   0%|          | 0/100 [00:00<?, ?ç”»åƒ/s]UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  daisy:   1%|          | 1/100 [00:01<02:09,  1.30s/ç”»åƒ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Debug: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: 7790614422_4557928ab9_n.jpg\n",
      "  Debug: 7790614422_4557928ab9_n.jpg - boxes: 1, phrases: ['daisy']\n",
      "  Debug: valid box[0]=[0.48365527391433716, 0.5085728168487549, 0.6819389462471008, 0.9050918221473694], logit=0.940\n",
      "  Debug: 1å€‹ã®æœ‰åŠ¹ãªãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  daisy:   2%|â–         | 2/100 [00:03<02:50,  1.74s/ç”»åƒ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Debug: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: 8709535323_a6bea3e43f.jpg\n",
      "  Debug: 8709535323_a6bea3e43f.jpg - boxes: 53, phrases: ['daisy', 'daisy', 'daisy']\n",
      "  Debug: valid box[0]=[0.16257236897945404, 0.6646108627319336, 0.12505637109279633, 0.11862374097108841], logit=0.624\n",
      "  Debug: valid box[1]=[0.2718833088874817, 0.47724610567092896, 0.1254427433013916, 0.15045975148677826], logit=0.681\n",
      "  Debug: valid box[2]=[0.7630153298377991, 0.8174995183944702, 0.11430664360523224, 0.12406367063522339], logit=0.542\n",
      "  Debug: valid box[3]=[0.049869876354932785, 0.5754499435424805, 0.09897541254758835, 0.10797804594039917], logit=0.573\n",
      "  Debug: valid box[4]=[0.4009813964366913, 0.7189937233924866, 0.17760835587978363, 0.13436336815357208], logit=0.401\n",
      "  Debug: valid box[5]=[0.2980276942253113, 0.8830457329750061, 0.09386725723743439, 0.10397042334079742], logit=0.529\n",
      "  Debug: valid box[6]=[0.5630061626434326, 0.8511745929718018, 0.0999787449836731, 0.0904737263917923], logit=0.511\n",
      "  Debug: valid box[7]=[0.49403223395347595, 0.6549654603004456, 0.1136590838432312, 0.13584384322166443], logit=0.538\n",
      "  Debug: valid box[8]=[0.02709037810564041, 0.7373160123825073, 0.053745537996292114, 0.11397042125463486], logit=0.510\n",
      "  Debug: valid box[9]=[0.7139130234718323, 0.5895143747329712, 0.09454162418842316, 0.0925145223736763], logit=0.512\n",
      "  Debug: valid box[10]=[0.3818412721157074, 0.6062905192375183, 0.08146081119775772, 0.08001403510570526], logit=0.497\n",
      "  Debug: valid box[11]=[0.09915664792060852, 0.9573847651481628, 0.12516848742961884, 0.08147984743118286], logit=0.439\n",
      "  Debug: valid box[12]=[0.024949321523308754, 0.8371643424034119, 0.049659449607133865, 0.09536254405975342], logit=0.420\n",
      "  Debug: valid box[13]=[0.4699757397174835, 0.9050593972206116, 0.10746077448129654, 0.12087161093950272], logit=0.438\n",
      "  Debug: valid box[14]=[0.8995991945266724, 0.9487250447273254, 0.10025113075971603, 0.09882495552301407], logit=0.342\n",
      "  Debug: valid box[15]=[0.11923299729824066, 0.8261294960975647, 0.0662539005279541, 0.060817405581474304], logit=0.409\n",
      "  Debug: valid box[16]=[0.41574349999427795, 0.8289528489112854, 0.09084387123584747, 0.08419124037027359], logit=0.392\n",
      "  Debug: valid box[17]=[0.39491984248161316, 0.9573951363563538, 0.11095190048217773, 0.08175847679376602], logit=0.382\n",
      "  Debug: valid box[19]=[0.6148273348808289, 0.5835779309272766, 0.041587844491004944, 0.055543359369039536], logit=0.385\n",
      "  Debug: valid box[20]=[0.6543756723403931, 0.7659600377082825, 0.08838870376348495, 0.09296340495347977], logit=0.426\n",
      "  Debug: valid box[21]=[0.8577635884284973, 0.8103467226028442, 0.06642468273639679, 0.08513952046632767], logit=0.364\n",
      "  Debug: valid box[22]=[0.6448681354522705, 0.9367862343788147, 0.09504915773868561, 0.11453194171190262], logit=0.338\n",
      "  Debug: valid box[23]=[0.9547439813613892, 0.8410307168960571, 0.0837615355849266, 0.10182102024555206], logit=0.344\n",
      "  Debug: valid box[24]=[0.6788153052330017, 0.8901939392089844, 0.05263063311576843, 0.0672449991106987], logit=0.320\n",
      "  Debug: valid box[26]=[0.2664041221141815, 0.6737653017044067, 0.08220008760690689, 0.08791179955005646], logit=0.337\n",
      "  Debug: valid box[50]=[0.8925845623016357, 0.9481766819953918, 0.07802695035934448, 0.09659652411937714], logit=0.329\n",
      "  Debug: valid box[52]=[0.9923930168151855, 0.6643380522727966, 0.013712603598833084, 0.0655331090092659], logit=0.380\n",
      "  Debug: 27å€‹ã®æœ‰åŠ¹ãªãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  daisy:   3%|â–         | 3/100 [00:04<02:23,  1.48s/ç”»åƒ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Debug: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: 14600779226_7bbc288d40_m.jpg\n",
      "  Debug: 14600779226_7bbc288d40_m.jpg - boxes: 28, phrases: ['daisy', 'daisy', 'daisy']\n",
      "  Debug: valid box[0]=[0.8381741642951965, 0.18074895441532135, 0.28748998045921326, 0.20416654646396637], logit=0.612\n",
      "  Debug: valid box[1]=[0.279735803604126, 0.8676998615264893, 0.3158825635910034, 0.1940205842256546], logit=0.591\n",
      "  Debug: valid box[2]=[0.12033975124359131, 0.3043748140335083, 0.24067367613315582, 0.1442079097032547], logit=0.531\n",
      "  Debug: valid box[3]=[0.39288556575775146, 0.15967893600463867, 0.2813572585582733, 0.1654309183359146], logit=0.552\n",
      "  Debug: valid box[4]=[0.4085979759693146, 0.42577728629112244, 0.22518213093280792, 0.19216695427894592], logit=0.543\n",
      "  Debug: valid box[5]=[0.7456232905387878, 0.7601636648178101, 0.2046668827533722, 0.17756742238998413], logit=0.535\n",
      "  Debug: valid box[6]=[0.5830586552619934, 0.844160258769989, 0.17688216269016266, 0.14654706418514252], logit=0.528\n",
      "  Debug: valid box[7]=[0.22511425614356995, 0.5286774039268494, 0.18230324983596802, 0.1274542659521103], logit=0.469\n",
      "  Debug: valid box[8]=[0.6976198554039001, 0.4237067997455597, 0.23245203495025635, 0.104924276471138], logit=0.429\n",
      "  Debug: valid box[10]=[0.731401264667511, 0.5585586428642273, 0.28560149669647217, 0.14847202599048615], logit=0.457\n",
      "  Debug: valid box[11]=[0.7660413384437561, 0.9822050929069519, 0.1745295226573944, 0.03546511009335518], logit=0.376\n",
      "  Debug: valid box[12]=[0.5108111500740051, 0.2477814108133316, 0.13352623581886292, 0.11587153375148773], logit=0.364\n",
      "  Debug: 12å€‹ã®æœ‰åŠ¹ãªãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  daisy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:41<00:00,  1.01s/ç”»åƒ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trainç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (76 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (19 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  å¤±æ•—ç”»åƒã‚’valã«ã‚³ãƒ”ãƒ¼ä¸­... (5 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  daisy (ã‚¯ãƒ©ã‚¹ID: 0): å‡¦ç†å®Œäº† (100 ç”»åƒ)\n",
      "  æ³¨æ„: å‹•ä½œç¢ºèªã®ãŸã‚ã€dandelionã¯100æšã®ã¿å‡¦ç†ã—ã¾ã™\n",
      "\n",
      "dandelion (ã‚¯ãƒ©ã‚¹ID: 1): ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  dandelion: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:28<00:00,  1.13ç”»åƒ/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trainç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (73 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (19 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  å¤±æ•—ç”»åƒã‚’valã«ã‚³ãƒ”ãƒ¼ä¸­... (8 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dandelion (ã‚¯ãƒ©ã‚¹ID: 1): å‡¦ç†å®Œäº† (100 ç”»åƒ)\n",
      "  æ³¨æ„: å‹•ä½œç¢ºèªã®ãŸã‚ã€rosesã¯100æšã®ã¿å‡¦ç†ã—ã¾ã™\n",
      "\n",
      "roses (ã‚¯ãƒ©ã‚¹ID: 2): ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  roses: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:29<00:00,  1.12ç”»åƒ/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trainç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (71 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (18 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  å¤±æ•—ç”»åƒã‚’valã«ã‚³ãƒ”ãƒ¼ä¸­... (11 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  roses (ã‚¯ãƒ©ã‚¹ID: 2): å‡¦ç†å®Œäº† (100 ç”»åƒ)\n",
      "  æ³¨æ„: å‹•ä½œç¢ºèªã®ãŸã‚ã€sunflowersã¯100æšã®ã¿å‡¦ç†ã—ã¾ã™\n",
      "\n",
      "sunflowers (ã‚¯ãƒ©ã‚¹ID: 3): ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  sunflowers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:23<00:00,  1.20ç”»åƒ/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trainç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (73 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (19 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  å¤±æ•—ç”»åƒã‚’valã«ã‚³ãƒ”ãƒ¼ä¸­... (8 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sunflowers (ã‚¯ãƒ©ã‚¹ID: 3): å‡¦ç†å®Œäº† (100 ç”»åƒ)\n",
      "  æ³¨æ„: å‹•ä½œç¢ºèªã®ãŸã‚ã€tulipsã¯100æšã®ã¿å‡¦ç†ã—ã¾ã™\n",
      "\n",
      "tulips (ã‚¯ãƒ©ã‚¹ID: 4): ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  tulips: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:27<00:00,  1.14ç”»åƒ/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trainç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (58 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... (15 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  å¤±æ•—ç”»åƒã‚’valã«ã‚³ãƒ”ãƒ¼ä¸­... (27 ç”»åƒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tulips (ã‚¯ãƒ©ã‚¹ID: 4): å‡¦ç†å®Œäº† (100 ç”»åƒ)\n",
      "\n",
      "å®Œäº†!\n",
      "ç·ç”»åƒæ•°: 500\n",
      "train: 351 ç”»åƒ\n",
      "val: 149 ç”»åƒ\n",
      "\n",
      "ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµ±è¨ˆ:\n",
      "  æˆåŠŸ: 441 ç”»åƒ (ã†ã¡ 351 ç”»åƒã‚’trainã€90 ç”»åƒã‚’valã«é…ç½®)\n",
      "  å¤±æ•—: 59 ç”»åƒ (å…¨ã¦valã«é…ç½®ã€ç”»åƒå…¨ä½“ã‚’ç¯„å›²ã¨ã—ã¦ä½¿ç”¨)\n",
      "\n",
      "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :\n",
      "  dataset/train/images/ - 359 ç”»åƒ\n",
      "  dataset/train/labels/ - 359 ãƒ©ãƒ™ãƒ«\n",
      "  dataset/val/images/ - 154 ç”»åƒ\n",
      "  dataset/val/labels/ - 154 ãƒ©ãƒ™ãƒ«\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# flowers_photos/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ã‚’ã€YOLOã®å­¦ç¿’ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã™ã‚‹ã€‚\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "# ã‚¯ãƒ©ã‚¹åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå -> ã‚¯ãƒ©ã‚¹IDï¼‰\n",
    "CLASS_MAPPING = {\n",
    "    'daisy': 0,\n",
    "    'dandelion': 1,\n",
    "    'roses': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4\n",
    "}\n",
    "\n",
    "# Grounding-DINOãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "GROUNDING_DINO_CONFIG_PATH = \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = \"groundingdino_swint_ogc.pth\"\n",
    "grounding_dino_model = None\n",
    "\n",
    "def load_grounding_dino():\n",
    "    \"\"\"Grounding-DINOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\"\"\"\n",
    "    global grounding_dino_model\n",
    "    \n",
    "    if not GROUNDING_DINO_AVAILABLE:\n",
    "        return None\n",
    "    \n",
    "    if grounding_dino_model is None:\n",
    "        try:\n",
    "            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ‘ã‚¹ã‚’ç¢ºèª\n",
    "            config_path = GROUNDING_DINO_CONFIG_PATH\n",
    "            checkpoint_path = GROUNDING_DINO_CHECKPOINT_PATH\n",
    "            \n",
    "            # ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’è©¦ã™\n",
    "            if not os.path.exists(config_path):\n",
    "                config_path = \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "            if not os.path.exists(checkpoint_path):\n",
    "                checkpoint_path = \"groundingdino_swint_ogc.pth\"\n",
    "                if not os.path.exists(checkpoint_path):\n",
    "                    checkpoint_path = \"GroundingDINO/weights/groundingdino_swint_ogc.pth\"\n",
    "            \n",
    "            grounding_dino_model = load_model(config_path, checkpoint_path)\n",
    "            print(\"Grounding-DINOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"Grounding-DINOãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
    "            print(\"groundingdino_swint_ogc.pthã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n",
    "            print(\"  wget https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\")\n",
    "            return None\n",
    "    return grounding_dino_model\n",
    "\n",
    "def get_cache_path(image_path, class_name):\n",
    "    \"\"\"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—\"\"\"\n",
    "    cache_dir = Path('.cache/annotations')\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ç”»åƒãƒ‘ã‚¹ã¨ã‚¯ãƒ©ã‚¹åã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ\n",
    "    cache_key = f\"{image_path}_{class_name}\"\n",
    "    cache_hash = hashlib.md5(cache_key.encode()).hexdigest()\n",
    "    return cache_dir / f\"{cache_hash}.json\"\n",
    "\n",
    "def get_annotation_with_grounding_dino(image_path, class_name, class_id, debug=False, min_confidence=0.3):\n",
    "    \"\"\"Grounding-DINOã‚’ä½¿ç”¨ã—ã¦ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰\n",
    "    \n",
    "    Args:\n",
    "        image_path: ç”»åƒã®ãƒ‘ã‚¹\n",
    "        class_name: ã‚¯ãƒ©ã‚¹åï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦ä½¿ç”¨ï¼‰\n",
    "        class_id: ã‚¯ãƒ©ã‚¹ID\n",
    "        debug: ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‹\n",
    "        min_confidence: æœ€å°ä¿¡é ¼åº¦ï¼ˆã“ã®å€¤ä»¥ä¸Šã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        (success, bboxes) - successãŒTrueã®å ´åˆã€bboxesã¯YOLOå½¢å¼ã®æ­£è¦åŒ–åº§æ¨™ã®ãƒªã‚¹ãƒˆ [[center_x, center_y, width, height], ...]\n",
    "                            å¤±æ•—ã—ãŸå ´åˆã¯None\n",
    "    \"\"\"\n",
    "    if not GROUNDING_DINO_AVAILABLE:\n",
    "        return False, None\n",
    "    \n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—\n",
    "    cache_path = get_cache_path(image_path, class_name)\n",
    "    \n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯èª­ã¿è¾¼ã‚€\n",
    "    cached_boxes = None\n",
    "    cached_logits = None\n",
    "    cached_phrases = None\n",
    "    \n",
    "    if cache_path.exists():\n",
    "        try:\n",
    "            with open(cache_path, 'r') as f:\n",
    "                cache_data = json.load(f)\n",
    "                if debug:\n",
    "                    print(f\"  Debug: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿: {image_path.name}\")\n",
    "                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰predictçµæœã‚’å¾©å…ƒ\n",
    "                if 'boxes' in cache_data and 'logits' in cache_data and 'phrases' in cache_data:\n",
    "                    cached_boxes = torch.tensor(cache_data['boxes'])\n",
    "                    cached_logits = torch.tensor(cache_data['logits'])\n",
    "                    cached_phrases = cache_data['phrases']\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"  Debug: ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç ´æã—ã¦ã„ã‚‹å ´åˆã¯å†è¨ˆç®—\n",
    "    \n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã¯äºˆæ¸¬ã‚’å®Ÿè¡Œ\n",
    "    if cached_boxes is None:\n",
    "        model = load_grounding_dino()\n",
    "        if model is None:\n",
    "            return False, None\n",
    "        \n",
    "        try:\n",
    "            # ç”»åƒã‚’èª­ã¿è¾¼ã¿\n",
    "            image_source, image = load_image(str(image_path))\n",
    "            \n",
    "            # ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè¤‡æ•°ã®å½¢å¼ã‚’è©¦ã™ï¼‰\n",
    "            # Grounding-DINOã¯ \"object .\" ã®å½¢å¼ã‚’å¥½ã‚€\n",
    "            text_prompt = f\"{class_name} .\"\n",
    "            box_threshold = 0.15  # ã‚ˆã‚Šä½ã„ã—ãã„å€¤ã«å¤‰æ›´\n",
    "            text_threshold = 0.10  # ã‚ˆã‚Šä½ã„ã—ãã„å€¤ã«å¤‰æ›´\n",
    "            \n",
    "            # äºˆæ¸¬ï¼ˆDEVICEå®šæ•°ã‚’ä½¿ç”¨ï¼‰\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=model,\n",
    "                image=image,\n",
    "                caption=text_prompt,\n",
    "                box_threshold=box_threshold,\n",
    "                text_threshold=text_threshold,\n",
    "                device=DEVICE\n",
    "            )\n",
    "            \n",
    "            # predictç›´å¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜\n",
    "            try:\n",
    "                cache_data = {\n",
    "                    'boxes': boxes.cpu().tolist() if isinstance(boxes, torch.Tensor) else boxes.tolist() if hasattr(boxes, 'tolist') else boxes,\n",
    "                    'logits': logits.cpu().tolist() if isinstance(logits, torch.Tensor) else logits.tolist() if hasattr(logits, 'tolist') else logits,\n",
    "                    'phrases': phrases\n",
    "                }\n",
    "                with open(cache_path, 'w') as f:\n",
    "                    json.dump(cache_data, f)\n",
    "                if debug:\n",
    "                    print(f\"  Debug: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: {image_path.name}\")\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(f\"  Debug: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            \n",
    "            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¤‰æ•°ã«è¨­å®š\n",
    "            cached_boxes = boxes\n",
    "            cached_logits = logits\n",
    "            cached_phrases = phrases\n",
    "            \n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"  Error: {image_path.name} - {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            return False, None\n",
    "    \n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯äºˆæ¸¬çµæœã‚’ä½¿ç”¨\n",
    "    boxes = cached_boxes\n",
    "    logits = cached_logits\n",
    "    phrases = cached_phrases\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"  Debug: {image_path.name} - boxes: {len(boxes)}, phrases: {phrases[:3] if len(phrases) > 0 else 'none'}\")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒå–å¾—ã§ããŸå ´åˆ\n",
    "        if len(boxes) > 0:\n",
    "            # boxesã¨logitsã®å½¢çŠ¶ã‚’ç¢ºèª\n",
    "            # boxesã¯ (n, 4) ã®å½¢çŠ¶ã€logitsã¯ (n,) ã®å½¢çŠ¶ã®ã¯ãš\n",
    "            if isinstance(boxes, torch.Tensor):\n",
    "                boxes = boxes.cpu()\n",
    "            if isinstance(logits, torch.Tensor):\n",
    "                logits = logits.cpu()\n",
    "            \n",
    "            # boxesãŒ2æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ«ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "            if boxes.dim() == 1:\n",
    "                # 1æ¬¡å…ƒã®å ´åˆã¯ (4,) ãªã®ã§ã€1ã¤ã®ãƒœãƒƒã‚¯ã‚¹ã¨ã—ã¦æ‰±ã†\n",
    "                boxes = boxes.unsqueeze(0)\n",
    "            elif boxes.dim() == 0:\n",
    "                # 0æ¬¡å…ƒã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼\n",
    "                if debug:\n",
    "                    print(f\"  Debug: boxesãŒ0æ¬¡å…ƒã§ã™ã€‚å½¢çŠ¶: {boxes.shape}\")\n",
    "                return False, None\n",
    "            \n",
    "            # logitsãŒ1æ¬¡å…ƒã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "            if logits.dim() == 0:\n",
    "                logits = logits.unsqueeze(0)\n",
    "            elif logits.dim() > 1:\n",
    "                # 2æ¬¡å…ƒä»¥ä¸Šã®å ´åˆã¯maxã‚’å–ã‚‹\n",
    "                logits = logits.max(dim=1)[0]\n",
    "            \n",
    "            # ä¿¡é ¼åº¦ãŒé–¾å€¤ä»¥ä¸Šã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å…¨ã¦å–å¾—\n",
    "            valid_boxes = []\n",
    "            # boxesã¨logitsã®é•·ã•ã‚’ç¢ºèª\n",
    "            num_boxes = boxes.shape[0] if boxes.dim() > 0 else 1\n",
    "            num_logits = logits.shape[0] if logits.dim() > 0 else 1\n",
    "            min_len = min(num_boxes, num_logits)\n",
    "            \n",
    "            for idx in range(min_len):\n",
    "                # boxã‚’å–å¾—ï¼ˆå½¢çŠ¶ãŒ (4,) ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰\n",
    "                if boxes.dim() == 2:\n",
    "                    box = boxes[idx]  # (4,)\n",
    "                elif boxes.dim() == 1:\n",
    "                    box = boxes  # æ—¢ã« (4,)\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(f\"  Debug: äºˆæœŸã—ãªã„boxesã®å½¢çŠ¶: {boxes.shape}\")\n",
    "                    continue\n",
    "                \n",
    "                # logitã‚’å–å¾—\n",
    "                if logits.dim() == 1:\n",
    "                    logit = logits[idx]\n",
    "                elif logits.dim() == 0:\n",
    "                    logit = logits\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(f\"  Debug: äºˆæœŸã—ãªã„logitsã®å½¢çŠ¶: {logits.shape}\")\n",
    "                    continue\n",
    "                \n",
    "                # logitã®å€¤ã‚’å–å¾—\n",
    "                if isinstance(logit, torch.Tensor):\n",
    "                    logit_value = logit.item()\n",
    "                else:\n",
    "                    logit_value = float(logit)\n",
    "                \n",
    "                if logit_value >= min_confidence:\n",
    "                    # boxã‚’numpyé…åˆ—ã«å¤‰æ›\n",
    "                    if isinstance(box, torch.Tensor):\n",
    "                        box_np = box.numpy()\n",
    "                    else:\n",
    "                        box_np = np.array(box)\n",
    "                    \n",
    "                    # box_npãŒ1æ¬¡å…ƒé…åˆ—ï¼ˆ4è¦ç´ ï¼‰ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "                    if box_np.ndim == 0:\n",
    "                        if debug:\n",
    "                            print(f\"  Debug: box_npãŒ0æ¬¡å…ƒã§ã™ã€‚box={box}, box_np={box_np}\")\n",
    "                        continue\n",
    "                    elif box_np.ndim > 1:\n",
    "                        box_np = box_np.flatten()\n",
    "                    \n",
    "                    if len(box_np) != 4:\n",
    "                        if debug:\n",
    "                            print(f\"  Debug: box_npã®è¦ç´ æ•°ãŒ4ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {len(box_np)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    center_x, center_y, width, height = box_np\n",
    "                    \n",
    "                    # åº§æ¨™ã‚’0-1ã®ç¯„å›²ã«ã‚¯ãƒ©ãƒ³ãƒ—\n",
    "                    center_x = max(0.0, min(1.0, float(center_x)))\n",
    "                    center_y = max(0.0, min(1.0, float(center_y)))\n",
    "                    width = max(0.001, min(1.0, float(width)))  # æœ€å°å€¤ã‚’0.001ã«è¨­å®š\n",
    "                    height = max(0.001, min(1.0, float(height)))  # æœ€å°å€¤ã‚’0.001ã«è¨­å®š\n",
    "                    \n",
    "                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒç”»åƒå†…ã«åã¾ã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "                    x_min = center_x - width / 2.0\n",
    "                    x_max = center_x + width / 2.0\n",
    "                    y_min = center_y - height / 2.0\n",
    "                    y_max = center_y + height / 2.0\n",
    "                    \n",
    "                    if 0 <= x_min < x_max <= 1 and 0 <= y_min < y_max <= 1:\n",
    "                        valid_boxes.append([center_x, center_y, width, height])\n",
    "                        if debug:\n",
    "                            print(f\"  Debug: valid box[{idx}]={[center_x, center_y, width, height]}, logit={logit_value:.3f}\")\n",
    "            \n",
    "            if len(valid_boxes) > 0:\n",
    "                if debug:\n",
    "                    print(f\"  Debug: {len(valid_boxes)}å€‹ã®æœ‰åŠ¹ãªãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—\")\n",
    "                return True, valid_boxes\n",
    "            elif debug:\n",
    "                print(f\"  Debug: ä¿¡é ¼åº¦{min_confidence}ä»¥ä¸Šã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "        \n",
    "        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆ\n",
    "        if debug:\n",
    "            print(f\"  Debug: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "        return False, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º\n",
    "        if debug:\n",
    "            print(f\"  Error: {image_path.name} - {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        return False, None\n",
    "\n",
    "def organize_yolo_dataset():\n",
    "    \"\"\"flower_photosãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ã‚’YOLOã®å­¦ç¿’å½¢å¼ã«å¤‰æ›\n",
    "    \n",
    "    - å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆdaisy, dandelion, roses, sunflowers, tulipsï¼‰ã”ã¨ã«ã‚¯ãƒ©ã‚¹ç•ªå·ã‚’å‰²ã‚ŠæŒ¯ã‚‹\n",
    "    - train/valã«åˆ†å‰²ã—ã¦ç§»å‹•\n",
    "    - å„ç”»åƒã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç¯„å›²ã¯ç”»é¢ã®å…¨é ˜åŸŸï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆdataset/ä»¥ä¸‹ã«é…ç½®ï¼‰\n",
    "    train_images_dir = Path('dataset/train/images')\n",
    "    train_labels_dir = Path('dataset/train/labels')\n",
    "    val_images_dir = Path('dataset/val/images')\n",
    "    val_labels_dir = Path('dataset/val/labels')\n",
    "    \n",
    "    for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Grounding-DINOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "    print(\"Grounding-DINOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    load_grounding_dino()\n",
    "    \n",
    "    # å„ã‚¯ãƒ©ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†\n",
    "    flowers_path = Path(FLOWERS_DIR)\n",
    "    total_images = 0\n",
    "    train_count = 0\n",
    "    val_count = 0\n",
    "    annotation_success_count = 0\n",
    "    annotation_fail_count = 0\n",
    "    \n",
    "    for class_name, class_id in CLASS_MAPPING.items():\n",
    "        class_dir = flowers_path / class_name\n",
    "        \n",
    "        if not class_dir.exists():\n",
    "            print(f\"è­¦å‘Š: {class_dir} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            continue\n",
    "        \n",
    "        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—\n",
    "        image_files = list(class_dir.glob('*.jpg'))\n",
    "        # å‹•ä½œç¢ºèªã®ãŸã‚ã€ã‚¯ãƒ©ã‚¹ã‚ãŸã‚Šç‰¹å®šæšæ•°ã ã‘å‡¦ç†\n",
    "        if MAX_IMAGES_PER_CLASS is not None and len(image_files) > MAX_IMAGES_PER_CLASS:\n",
    "            image_files = image_files[:MAX_IMAGES_PER_CLASS]\n",
    "            print(f\"  æ³¨æ„: å‹•ä½œç¢ºèªã®ãŸã‚ã€{class_name}ã¯{MAX_IMAGES_PER_CLASS}æšã®ã¿å‡¦ç†ã—ã¾ã™\")\n",
    "        total_images += len(image_files)\n",
    "        \n",
    "        # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«\n",
    "        random.shuffle(image_files)\n",
    "        \n",
    "        # æˆåŠŸã—ãŸç”»åƒã¨å¤±æ•—ã—ãŸç”»åƒã‚’åˆ†ã‘ã¦å‡¦ç†\n",
    "        success_images = []  # (img_path, bbox) ã®ãƒªã‚¹ãƒˆ\n",
    "        fail_images = []  # img_path ã®ãƒªã‚¹ãƒˆ\n",
    "        \n",
    "        # å„ç”»åƒã‚’å‡¦ç†ã—ã¦ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼ˆé€²æ—ãƒãƒ¼ä»˜ãï¼‰\n",
    "        print(f\"\\n{class_name} (ã‚¯ãƒ©ã‚¹ID: {class_id}): ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ä¸­...\")\n",
    "        for idx, img_path in enumerate(tqdm(image_files, desc=f\"  {class_name}\", unit=\"ç”»åƒ\")):\n",
    "            # æœ€åˆã®æ•°æšã®ç”»åƒã§ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º\n",
    "            debug_mode = (idx < 3) and (class_name == list(CLASS_MAPPING.keys())[0])\n",
    "            \n",
    "            # Grounding-DINOã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—\n",
    "            success, bboxes = get_annotation_with_grounding_dino(img_path, class_name, class_id, debug=debug_mode)\n",
    "            \n",
    "            if success:\n",
    "                success_images.append((img_path, bboxes))\n",
    "                annotation_success_count += 1\n",
    "            else:\n",
    "                fail_images.append(img_path)\n",
    "                annotation_fail_count += 1\n",
    "        \n",
    "        # æˆåŠŸã—ãŸç”»åƒã‚’train/valã«åˆ†å‰²\n",
    "        random.shuffle(success_images)\n",
    "        split_idx = int(len(success_images) * TRAIN_FRACTION)\n",
    "        success_train = success_images[:split_idx]\n",
    "        success_val = success_images[split_idx:]\n",
    "        \n",
    "        # æˆåŠŸã—ãŸç”»åƒã®trainåˆ†ã‚’å‡¦ç†ï¼ˆé€²æ—ãƒãƒ¼ä»˜ãï¼‰\n",
    "        if len(success_train) > 0:\n",
    "            print(f\"  trainç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... ({len(success_train)} ç”»åƒ)\")\n",
    "            # YOLOã¯1ç”»åƒã‚ãŸã‚Šæœ€å¤§300å€‹ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å‡¦ç†å¯èƒ½\n",
    "            MAX_BOXES_PER_IMAGE = 300\n",
    "            for img_path, bboxes in tqdm(success_train, desc=\"    train\", unit=\"ç”»åƒ\", leave=False):\n",
    "                dest_img = train_images_dir / img_path.name\n",
    "                shutil.copy2(img_path, dest_img)\n",
    "                \n",
    "                # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆè¤‡æ•°ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã«å¯¾å¿œï¼‰\n",
    "                label_path = train_labels_dir / (img_path.stem + '.txt')\n",
    "                # Pythonå´ã§æ–‡å­—åˆ—ã‚’çµåˆã—ã¦ã‹ã‚‰ä¸€æ‹¬æ›¸ãè¾¼ã¿ï¼ˆæ€§èƒ½å‘ä¸Šã®ãŸã‚ï¼‰\n",
    "                label_lines = [\n",
    "                    f\"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\"\n",
    "                    for bbox in bboxes[:MAX_BOXES_PER_IMAGE]\n",
    "                ]\n",
    "                with open(label_path, 'w') as f:\n",
    "                    # YOLOå½¢å¼: class_id center_x center_y width height (æ­£è¦åŒ–åº§æ¨™)\n",
    "                    f.writelines(label_lines)\n",
    "                \n",
    "                train_count += 1\n",
    "        \n",
    "        # æˆåŠŸã—ãŸç”»åƒã®valåˆ†ã‚’å‡¦ç†ï¼ˆé€²æ—ãƒãƒ¼ä»˜ãï¼‰\n",
    "        if len(success_val) > 0:\n",
    "            print(f\"  valç”¨ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ä¸­... ({len(success_val)} ç”»åƒ)\")\n",
    "            for img_path, bboxes in tqdm(success_val, desc=\"    val\", unit=\"ç”»åƒ\", leave=False):\n",
    "                dest_img = val_images_dir / img_path.name\n",
    "                shutil.copy2(img_path, dest_img)\n",
    "                \n",
    "                # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆGrounding-DINOã§å–å¾—ã—ãŸã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ï¼‰\n",
    "                label_path = val_labels_dir / (img_path.stem + '.txt')\n",
    "                # Pythonå´ã§æ–‡å­—åˆ—ã‚’çµåˆã—ã¦ã‹ã‚‰ä¸€æ‹¬æ›¸ãè¾¼ã¿ï¼ˆæ€§èƒ½å‘ä¸Šã®ãŸã‚ï¼‰\n",
    "                label_lines = [\n",
    "                    f\"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\"\n",
    "                    for bbox in bboxes[:MAX_BOXES_PER_IMAGE]\n",
    "                ]\n",
    "\n",
    "                with open(label_path, 'w') as f:\n",
    "                    # YOLOå½¢å¼: class_id center_x center_y width height (æ­£è¦åŒ–åº§æ¨™)\n",
    "                    f.writelines(label_lines)\n",
    "                                \n",
    "                val_count += 1\n",
    "        \n",
    "        # å¤±æ•—ã—ãŸç”»åƒã¯å…¨ã¦valã«è¿½åŠ ï¼ˆç”»åƒå…¨ä½“ã‚’ç¯„å›²ã¨ã—ã¦ï¼‰ï¼ˆé€²æ—ãƒãƒ¼ä»˜ãï¼‰\n",
    "        if len(fail_images) > 0:\n",
    "            print(f\"  å¤±æ•—ç”»åƒã‚’valã«ã‚³ãƒ”ãƒ¼ä¸­... ({len(fail_images)} ç”»åƒ)\")\n",
    "            for img_path in tqdm(fail_images, desc=\"    val(fail)\", unit=\"ç”»åƒ\", leave=False):\n",
    "                dest_img = val_images_dir / img_path.name\n",
    "                shutil.copy2(img_path, dest_img)\n",
    "                \n",
    "                # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç¯„å›²ã¯ç”»é¢ã®å…¨é ˜åŸŸï¼‰\n",
    "                label_path = val_labels_dir / (img_path.stem + '.txt')\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write(f\"{class_id} 0.5 0.5 1.0 1.0\\n\")\n",
    "                \n",
    "                val_count += 1\n",
    "        \n",
    "        print(f\"  {class_name} (ã‚¯ãƒ©ã‚¹ID: {class_id}): å‡¦ç†å®Œäº† ({len(image_files)} ç”»åƒ)\")\n",
    "    \n",
    "    print(f\"\\nå®Œäº†!\")\n",
    "    print(f\"ç·ç”»åƒæ•°: {total_images}\")\n",
    "    print(f\"train: {train_count} ç”»åƒ\")\n",
    "    print(f\"val: {val_count} ç”»åƒ\")\n",
    "    print(f\"\\nã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµ±è¨ˆ:\")\n",
    "    print(f\"  æˆåŠŸ: {annotation_success_count} ç”»åƒ (ã†ã¡ {train_count} ç”»åƒã‚’trainã€{annotation_success_count - train_count} ç”»åƒã‚’valã«é…ç½®)\")\n",
    "    print(f\"  å¤±æ•—: {annotation_fail_count} ç”»åƒ (å…¨ã¦valã«é…ç½®ã€ç”»åƒå…¨ä½“ã‚’ç¯„å›²ã¨ã—ã¦ä½¿ç”¨)\")\n",
    "    print(f\"\\nãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :\")\n",
    "    print(f\"  dataset/train/images/ - {len(list(train_images_dir.glob('*.jpg')))} ç”»åƒ\")\n",
    "    print(f\"  dataset/train/labels/ - {len(list(train_labels_dir.glob('*.txt')))} ãƒ©ãƒ™ãƒ«\")\n",
    "    print(f\"  dataset/val/images/ - {len(list(val_images_dir.glob('*.jpg')))} ç”»åƒ\")\n",
    "    print(f\"  dataset/val/labels/ - {len(list(val_labels_dir.glob('*.txt')))} ãƒ©ãƒ™ãƒ«\")\n",
    "\n",
    "# å®Ÿè¡Œ\n",
    "organize_yolo_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23179c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.229 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.228 ğŸš€ Python-3.12.2 torch-2.9.1 MPS (Apple M5)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/matsuda-t/workspace-personal/YOLO-flower/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 599.7Â±634.0 MB/s, size: 65.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/matsuda-t/workspace-personal/YOLO-flower/dataset/train/labels... 359 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 359/359 5.8Kit/s 0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/matsuda-t/workspace-personal/YOLO-flower/dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 595.2Â±677.9 MB/s, size: 98.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/matsuda-t/workspace-personal/YOLO-flower/dataset/val/labels... 154 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 154/154 4.5Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/matsuda-t/workspace-personal/YOLO-flower/dataset/val/labels.cache\n",
      "Plotting labels to /Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/10      11.5G      2.729      4.394      2.647         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.2it/s 37.9s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.1s/it 21.0s.4s\n",
      "                   all        154        553    0.00361      0.361     0.0236      0.011\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/10      3.55G      2.527      4.091      2.537         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.5it/s 30.6s0.6ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 3.5s/it 18.7s<14.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 3.4s/it 21.9s<10.3sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.5s/it 25.5s<7.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.1s/it 31.0s.5s\n",
      "                   all        154        553       0.23     0.0263     0.0126    0.00383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/10      3.54G      2.236      3.804      2.271         63        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.5it/s 29.4s0.7ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 11.9s/it 3.6s<1:47WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 6.9s/it 7.1s<55.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.4s/it 10.6s<37.7sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.7s/it 14.3s<28.4sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.2s/it 17.5s<20.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 4.0s/it 21.1s<15.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 3.9s/it 24.8s<11.6sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.7s/it 28.2s<7.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 3.6s/it 31.6s<3.6sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.5s/it 34.8s\n",
      "                   all        154        553      0.016     0.0623    0.00732    0.00284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/10       3.5G      2.112      3.632      2.147         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.4it/s 32.9s0.7ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 12.1s/it 3.6s<1:49WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 7.2s/it 7.3s<57.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.6s/it 11.0s<39.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.8s/it 14.6s<28.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.2s/it 18.0s<21.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 4.1s/it 21.7s<16.3sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 3.8s/it 24.9s<11.3sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.7s/it 28.4s<7.4sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 3.6s/it 31.8s<3.6sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.5s/it 35.0s\n",
      "                   all        154        553     0.0228      0.064    0.00991    0.00376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/10      3.52G      2.017      3.466       2.08         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.2it/s 38.2s0.9ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 12.1s/it 3.6s<1:49WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 7.0s/it 7.2s<56.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.5s/it 10.9s<38.6sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.7s/it 14.4s<28.4sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.4s/it 18.3s<22.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 4.1s/it 21.8s<16.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 4.0s/it 25.5s<11.9sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.9s/it 29.3s<7.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 3.7s/it 32.6s<3.7sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.6s/it 35.9s\n",
      "                   all        154        553     0.0372      0.134     0.0176    0.00713\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/10      3.48G      1.918      3.364       1.96         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.3it/s 35.5s0.8ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 11.9s/it 3.6s<1:47WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 6.5s/it 6.7s<52.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.1s/it 10.1s<35.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.7s/it 14.0s<28.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.2s/it 17.5s<21.1sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 3.9s/it 20.7s<15.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 3.7s/it 24.0s<11.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.6s/it 27.3s<7.1sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 3.6s/it 31.1s<3.6sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.4s/it 34.0s\n",
      "                   all        154        553      0.025     0.0858     0.0141    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/10      3.48G      1.835      3.172      1.894         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.4it/s 33.2s0.6ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 11.6s/it 3.5s<1:45WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 7.0s/it 7.1s<56.1sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.3s/it 10.5s<36.9sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.8s/it 14.4s<28.7sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.3s/it 17.9s<21.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 3.9s/it 21.0s<15.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 3.8s/it 24.8s<11.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.9s/it 28.7s<7.7sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 3.7s/it 32.1s<3.7sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.5s/it 35.4s\n",
      "                   all        154        553      0.091     0.0789     0.0457      0.021\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/10      3.45G      1.754      3.075      1.849         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.0it/s 43.6s1.2ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 11.5s/it 3.4s<1:43WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 6.6s/it 6.7s<52.6sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.1s/it 10.1s<35.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.5s/it 13.7s<27.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.4s/it 17.8s<21.9sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 4.0s/it 21.1s<16.1sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 4.4s/it 26.7s<13.1sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 4.2s/it 30.6s<8.4sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 4.0s/it 34.1s<4.0sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.7s/it 37.0s\n",
      "                   all        154        553      0.118      0.103     0.0485      0.027\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/10      3.47G      1.713       2.95      1.756         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.3it/s 35.5s0.8ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 12.6s/it 3.8s<1:53WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 6.7s/it 7.0s<53.6sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.2s/it 10.4s<36.6sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.5s/it 13.8s<26.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.0s/it 17.0s<20.1sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 3.8s/it 20.3s<15.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 3.6s/it 23.7s<10.9sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.7s/it 27.4s<7.4sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 3.6s/it 30.9s<3.6sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.4s/it 33.9s\n",
      "                   all        154        553      0.103       0.13     0.0662      0.035\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/10      3.47G      1.647      2.891      1.719         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 1.3it/s 34.2s0.6ss\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 11.3s/it 3.4s<1:42WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 6.7s/it 6.8s<53.5sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 5.0s/it 10.0s<35.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 4.4s/it 13.4s<26.4sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 4.0s/it 16.7s<20.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 3.8s/it 20.0s<15.1sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 3.6s/it 23.3s<10.8sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 3.5s/it 26.6s<7.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 3.4s/it 29.9s<3.4sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.3s/it 32.9s\n",
      "                   all        154        553       0.13      0.141     0.0712     0.0414\n",
      "\n",
      "10 epochs completed in 0.191 hours.\n",
      "Optimizer stripped from /Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5/weights/best.pt...\n",
      "Ultralytics 8.3.228 ğŸš€ Python-3.12.2 torch-2.9.1 MPS (Apple M5)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 10% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/10 20.4s/it 6.1s<3:04WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/10 9.3s/it 10.2s<1:14WARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 3/10 7.3s/it 15.1s<51.3sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 40% â”â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€ 4/10 6.5s/it 20.3s<39.2sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 5/10 6.0s/it 25.4s<30.0sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 60% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 6/10 4.9s/it 28.9s<19.7sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 7/10 5.1s/it 34.5s<15.3sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 8/10 5.1s/it 39.6s<10.3sWARNING âš ï¸ NMS time limit 2.800s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 90% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 9/10 4.7s/it 43.5s<4.7sWARNING âš ï¸ NMS time limit 2.500s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 4.8s/it 48.1s\n",
      "                   all        154        553      0.157      0.137     0.0928     0.0542\n",
      "                 daisy         26         92       0.12      0.087     0.0425     0.0265\n",
      "             dandelion         28         56       0.18     0.0893     0.0741     0.0431\n",
      "                 roses         30         96      0.186      0.135      0.111     0.0812\n",
      "            sunflowers         27        241      0.209      0.361      0.195      0.104\n",
      "                tulips         43         68     0.0879     0.0147     0.0421     0.0161\n",
      "Speed: 1.2ms preprocess, 41.6ms inference, 0.0ms loss, 193.3ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5\u001b[0m\n",
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2, 3, 4])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x141385280>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  1.3483e-05,  6.7413e-06,           0],\n",
      "       [        0.5,         0.5,         0.5, ...,  3.2316e-05,  1.6158e-05,           0],\n",
      "       [          1,           1,           1, ...,  2.5898e-05,  1.2949e-05,           0],\n",
      "       [          1,           1,           1, ...,  0.00014927,  7.4635e-05,           0],\n",
      "       [        0.2,         0.2,         0.2, ...,  6.6948e-05,  3.3474e-05,           0]], shape=(5, 1000)), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0079724,   0.0079724,   0.0084083, ...,           0,           0,           0],\n",
      "       [   0.016433,    0.016433,    0.017771, ...,           0,           0,           0],\n",
      "       [   0.012771,    0.012771,    0.013469, ...,           0,           0,           0],\n",
      "       [   0.033298,    0.033298,    0.035736, ...,           0,           0,           0],\n",
      "       [   0.023182,    0.023182,    0.024599, ...,           0,           0,           0]], shape=(5, 1000)), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0040261,   0.0040261,   0.0042486, ...,           1,           1,           1],\n",
      "       [  0.0083591,   0.0083591,   0.0090525, ...,           1,           1,           1],\n",
      "       [  0.0064681,   0.0064681,   0.0068262, ...,           1,           1,           1],\n",
      "       [   0.017016,    0.017016,    0.018292, ...,           1,           1,           1],\n",
      "       [   0.011803,    0.011803,    0.012538, ...,           1,           1,           1]], shape=(5, 1000)), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.40217,     0.40217,     0.40217, ...,           0,           0,           0],\n",
      "       [    0.48214,     0.48214,     0.48214, ...,           0,           0,           0],\n",
      "       [        0.5,         0.5,         0.5, ...,           0,           0,           0],\n",
      "       [    0.77178,     0.77178,     0.77178, ...,           0,           0,           0],\n",
      "       [    0.64706,     0.64706,     0.64706, ...,           0,           0,           0]], shape=(5, 1000)), 'Confidence', 'Recall']]\n",
      "fitness: np.float64(0.05419790895424317)\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([   0.026455,    0.043059,    0.081234,     0.10413,    0.016113])\n",
      "names: {0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers', 4: 'tulips'}\n",
      "nt_per_class: array([ 92,  56,  96, 241,  68])\n",
      "nt_per_image: array([26, 28, 30, 27, 43])\n",
      "results_dict: {'metrics/precision(B)': 0.15659787572063816, 'metrics/recall(B)': 0.1374721271333718, 'metrics/mAP50(B)': 0.09278123683941131, 'metrics/mAP50-95(B)': 0.05419790895424317, 'fitness': 0.05419790895424317}\n",
      "save_dir: PosixPath('/Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/train5')\n",
      "speed: {'preprocess': 1.2489764553543132, 'inference': 41.57274647981727, 'loss': 9.822051415776277e-05, 'postprocess': 193.30691151221149}\n",
      "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
      "task: 'detect'\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data=str((Path.cwd() / 'data.yaml').resolve()),  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼‰\n",
    "    epochs=10,  # å­¦ç¿’å›æ•°\n",
    "    batch=8,  # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    imgsz=640,  # ç”»åƒã‚µã‚¤ã‚ºï¼ˆå…¥åŠ›ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºï¼‰\n",
    "    device=DEVICE  # CPU åˆã¯ GPUï¼ˆCUDAï¼‰\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c4dcf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228 ğŸš€ Python-3.12.2 torch-2.9.1 MPS (Apple M5)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 210.7Â±70.2 MB/s, size: 49.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/matsuda-t/workspace-personal/YOLO-flower/dataset/val/labels.cache... 154 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 154/154 592.6Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 1.7s/it 33.9s0.6s\n",
      "                   all        154        553      0.239      0.146      0.133     0.0755\n",
      "                 daisy         26         92      0.192       0.12     0.0883     0.0476\n",
      "             dandelion         28         56      0.283      0.107      0.112     0.0671\n",
      "                 roses         30         96      0.262     0.0938      0.119     0.0785\n",
      "            sunflowers         27        241      0.259      0.382      0.292      0.163\n",
      "                tulips         43         68      0.201     0.0294     0.0515     0.0215\n",
      "Speed: 0.5ms preprocess, 104.2ms inference, 0.0ms loss, 85.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/matsuda-t/workspace-personal/YOLO-flower/runs/detect/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# è¿½åŠ å­¦ç¿’å¾Œã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼‰\n",
    "model = YOLO(results.save_dir / 'weights' / 'best.pt')  # \"best.pt\" ã¯æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«\n",
    "\n",
    "# æ¤œè¨¼ã‚’å®Ÿæ–½\n",
    "results = model.val(\n",
    "    data=str((Path.cwd() / 'data.yaml').resolve()),  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼‰\n",
    "    batch=8,  # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    imgsz=640,  # ç”»åƒã‚µã‚¤ã‚ºï¼ˆå…¥åŠ›ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºï¼‰\n",
    "    device=DEVICE,  # CPU ã¾ãŸã¯ GPUï¼ˆCUDAï¼‰\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
